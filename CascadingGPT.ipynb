{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/341-final/blob/main/CascadingGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WzYfxlVTsoJ"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XwPXWWuU9ug"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import pylab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrADmhagesI7",
        "outputId": "2aa6c494-c9b1-4489-de23-16bcb0d546c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"type\": \"prompts\",\n",
            "  \"text\": [\n",
            "    \"Introduction to Prompt Engineering\",\n",
            "    \"The Fundamentals of Prompt Engineering\",\n",
            "    \"Advanced Techniques in Prompt Engineering\",\n",
            "    \"Practical Applications of Prompt Engineering\",\n",
            "    \"The Future of Prompt Engineering\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"type\": \"prompts\",\n",
            "  \"text\": [\n",
            "    \"What is Prompt Engineering?\",\n",
            "    \"The Importance of Prompt Engineering\",\n",
            "    \"The Evolution of Prompt Engineering\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "client = OpenAI(api_key=userdata.get('key'))\n",
        "final = \"\"\n",
        "stack = [{\"role\":\"system\",\"content\":\"Expect total about 5k words. Create a blog on prompt engineering, ensuring it has a minimum of three layers. Utilize the method of recursion - identifying whether a topic can be addressed in one go or if it necessitates further breakdown. If a topic can be presented directly, proceed with it. However, if it requires further subdivision, create an outline consisting of numerous sub-prompts, calling the main section for these subsections. Make sure that each prompt provides informative content. Deliver responses in JSON format, has to be one of {type:'response', text: 'text here'} or {type:'prompts', text: ['sub prompt1', 'sub prompt2']}. Remember, only JSON outputs are to be provided - avoid placing JSON within code blocks. As only the response (not the prompt) will be visible to the user, ensure to include subtitles in the final response too. Always commence with an outline as your first response.\"}]\n",
        "def generate(stack):\n",
        "  global final\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    # model=\"gpt-3.5-turbo-1106\",\n",
        "    response_format={ \"type\": \"json_object\" },\n",
        "    messages=stack,\n",
        "  )\n",
        "  stack.append({\"role\":\"assistant\",\"content\":response.choices[0].message.content})\n",
        "  print(response.choices[0].message.content)\n",
        "  res = json.loads(response.choices[0].message.content)\n",
        "  if res[\"type\"]==\"response\":\n",
        "    final=(final + res[\"text\"])\n",
        "    stack = stack[:-1]\n",
        "    return\n",
        "  else:\n",
        "    for i in res[\"text\"]:\n",
        "      stack.append({\"role\":\"user\",\"content\":\"Now you write the subsection of \"+i})\n",
        "      generate(stack)\n",
        "      stack = stack[:-1]\n",
        "  stack = stack[:-1]\n",
        "\n",
        "generate(stack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE2fgLe63A1T"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "client = OpenAI(api_key=userdata.get('key'))\n",
        "final2 = \"\"\n",
        "# task = \"generate a guidebook for prompt engineering for GPT in Chinese, this should be long and detailed.\"\n",
        "def generate(prompt, d):\n",
        "  global final2\n",
        "  response = client.chat.completions.create(\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "    response_format={ \"type\": \"json_object\" },\n",
        "    messages=[{\"role\":\"system\",\"content\":\"Create a blog on prompt engineering, ensuring it has a minimum of three layers. Utilize the method of recursion - identifying whether a topic can be addressed in one go or if it necessitates further breakdown. If a topic can be presented directly, proceed with it. However, if it requires further subdivision, create an outline consisting of numerous sub-prompts, calling the main section for these subsections. Make sure that each prompt provides informative content. Deliver responses in JSON format, has to be one of {type:'response', text: 'text here'} or {type:'prompts', text: ['sub prompt1', 'sub prompt2']}. Remember, only JSON outputs are to be provided - avoid placing JSON within code blocks. As only the response (not the prompt) will be visible to the user, ensure to include subtitles in the final response too. Always commence with an outline as your first response.\"}, {\"role\":\"user\",\"content\":\"Now write about \"+prompt+\". And now you are in nested level \"+str(d)}],\n",
        "  )\n",
        "  res = json.loads(response.choices[0].message.content)\n",
        "  print(res)\n",
        "  if res[\"type\"]==\"response\":\n",
        "    final2 += (res[\"text\"])\n",
        "    return\n",
        "  else:\n",
        "    for i in res[\"text\"]:\n",
        "      generate(i, d+1)\n",
        "generate(\"The main outline\", 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Judge which book is better. \\n\\nBook 1:\"+final+\"\\n\\nBook2:\"+final2}],\n",
        "  )"
      ],
      "metadata": {
        "id": "G8Ei66on6QIK"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITDpSJ16AVma",
        "outputId": "5369af25-38d3-4ef2-906b-1ef1bad5164e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI developed by OpenAI, I cannot provide subjective opinions or judgments, but I can help you compare and analyze these texts. Both Book 1 and Book 2 offer insights into the field of prompt engineering, but they differ in structure, depth, and the range of topics they cover.\n",
            "\n",
            "Book 1 provides an extensive, detailed look into the subject, breaking down various aspects of prompt engineering into well-structured chapters. It covers the importance and historical context of prompt engineering, the connection with AI, the roles of prompts in machine learning, effective prompt components, and types. It further delves into techniques and strategies for prompt creation, iterative development, applications across different AI domains, and relevant tools and resources. Notably, it also discusses advanced topics such as chain-of-thought prompting, few-shot and zero-shot learning, and considerations for large language models (LLMs) and transfer learning, along with hyperparameter optimization in prompt engineering.\n",
            "\n",
            "Book 2, based on the excerpt provided, introduces prompt engineering and its importance in optimizing AI interaction. It appears to be concise and offers an introduction to the topic, possibly serving as a primer to the field. However, it's hard to determine the full scope and depth of its content without more details or a table of contents.\n",
            "\n",
            "If you're seeking comprehensive coverage of the topic, including advanced strategies, practical applications, and consideration of technical aspects within AI systems, **Book 1** seems to be the more thorough and detailed resource. It would likely be well-suited for readers who have a firm understanding of AI and are looking to dive into specific methodologies and complex facets of prompt engineering.\n",
            "\n",
            "On the other hand, if you're looking for a brief overview or a more approachable entry point into the subject without getting into the minutiae, **Book 2** may serve as a good introduction. It seems to cater to beginners or those who want a quick comprehension of the basics of prompt engineering.\n",
            "\n",
            "Ultimately, the \"better\" book would depend on your specific needs, level of expertise, and the depth of knowledge you seek in the field of prompt engineering.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ans.txt\",\"a\") as f:\n",
        "  f.write(f\"With path info: {final} Without: {final2} GPT's judge: {response.choices[0].message.content}\")"
      ],
      "metadata": {
        "id": "BLeU-senAKw7"
      },
      "execution_count": 115,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM89ieTcqvNXNNUf+WQ0z8m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}